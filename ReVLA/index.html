<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content=" Regaining the Vision capabilities of Robotic Foundational Models ">
  <meta name="keywords" content="Robotics Foundational Model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ReVLA: Reverting Visual Domain Limitation
    of Robotic Foundation Models</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://sombit888.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

    </div>

  </div>
</nav>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">ReVLA: Reverting Visual Domain Limitation
            of Robotic Foundation Models</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://sombit888.github.io">Sombit Dey</a><sup>1</sup>,</span>
            <span class="author-block">
            <!-- just the names , no hrefs  -->
            
              <a href="https://jannicozaech.github.io/">Jan-Nico</a><sup>1</sup>,</span>
            <span class="author-block">
              Nikolay Nikolov<sup>1</sup>,
            </span>
            <span class="author-block">
              Danda Paudel<sup>1</sup>,
            </span>
            <span class="author-block">
              Luc Van Gool<sup>1</sup>,
            </span>
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup><a href="https://insait.ai/">INSAIT, Sofia University ‚ÄúSt. Kliment Ohridski‚Äù
            </a></span>
            <!-- <span class="author-block"><sup>2</sup></span> -->
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2409.15250"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> 

              <span class="link-block">
                <a href="https://arxiv.org/abs/2409.15250"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. --> 
              <!-- <span class="link-block">
                <a href="https://github.com/sombit888/openvla"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
              <span class="link-block">
                <a href="https://huggingface.co/Insait-Robotics" 
                   class="external-link button is-normal is-rounded is-dark" target="_blank">
                  <span class="icon">
                    <img src="https://huggingface.co/datasets/huggingface/brand-assets/raw/main/hf-logo.png" 
                         alt="Hugging Face Logo" style="height: 20px; vertical-align: middle;">
                  </span>
                  <span>Hugging Face</span>
                </a>
              </span>

              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
      <!-- add a image src -->
      <img src="./static/images/ReVLA.jpg" alt="teaser image">


      <h2 class="subtitle has-text-centered">
        ReVLA aims to improve the visual domain capabilities of Robotic Foundational Models like OpenVLA. 
        forgetting, we propose a gradual backbone reversal approach
        founded on model merging. This enables OpenVLA which
        requires the adaptation of the visual backbones during initial
        training to regain its visual generalization ability.
      </h2>
    </div>
  </div>
</section>

<section>
  <hr style="border: 1px solid black;">
  <!-- Hardware experiments results   -->
  <div class="container is-max-desktop" style="text-align: center;">
    <h2 class="title is-3">Hardware Experiments</h2>
    <h2 class="subtitle is-5">We test ReVLA on bridge robot and compare it with the OpenVLA. 
      The robot is prompted with language instruction and a single 3rd person view uncaliberated image. 
    </h2>
    <div class="columns is-centered">
      

    <table style="border-collapse: separate; border-spacing: 15px;">
      <tr>
        <th>Task</th>
        <th>ReVLA</th>
        <th>OpenVLA</th>
        <!-- <th>Comments</th> -->
    </tr>
    <tr>
        <td>Pick up the lobster and place it on the plate( Testing OOD Objects)</td>
        <td>4/10</td>
        <td>0/10</td>
        <!-- <td>Lobster is highly OOD and showcases the strength of using a frozen vision backbone</td> -->
    </tr>
    <tr>
        <td>Place the cup on the blue plate (Testing Visual Recognition)</td>
        <td>5/10</td>
        <td>2/10</td>
        <!-- <td>Redo if possible (hardware failure üòü), for ReVLA</td> -->
    </tr>
    <tr>
        <td>Pick up banana and place it in the pan (Indomain Task)</td>
        <td>8/10</td>
        <td>9/10</td>
        <!-- <td></td> -->
    </tr>
  </table>
  
</section>
<br>
<br>
<h4> We further tried Openvla-Bridge but it performs worse than OpenVLA, hence we compare only with OpenVLA.</h4>

<hr style="border: 1px solid black;">
<!-- Write a section with 3 rows and two columns of videos  -->
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-4">
          <h2 class="title is-3">Hardware Experiments</h2>
          <p>
            We demonstrate the capabilities of our method on a real robot, in this case the Widowx robot. 
            The robot is prompted with language instruction and a single 3rd person view uncaliberated image.
            </p>

            <br>

            <div style="display: flex; justify-content: center; align-items: flex-start; gap: 20px;">
              <!-- Video 1 with Caption Below -->
              <div style="display: flex; flex-direction: column; align-items: center; width: 45%;">
                <video id="dollyzoom1" autoplay controls muted loop playsinline style="width: 100%;">
                  <source src="./static/videos/ReVLA_flip_bridge/Pick up the lobster and place it on the plate/1-rollout.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <p style="margin-top: 10px; font-size: 1em;">ReVLA</p>
              </div>
            
  
              <div style="display: flex; flex-direction: column; align-items: center; width: 45%;">
                <video id="dollyzoom1" autoplay controls muted loop playsinline style="width: 100%;">
                  <source src="./static/videos/openvla-7b/Pick up the lobster and place it on the plate/1-rollout.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <p style="margin-top: 10px; font-size: 1em;">OpenVLA</p>
              </div>
            </div>
            <p style="text-align: center;">
              Task Prompt : Pick up the Lobster  and place it on the plate  
            </p>
            <!-- add a blank space -->
            <br>

            <div style="display: flex; justify-content: center; align-items: flex-start; gap: 20px;">
              <!-- Video 1 with Caption Below -->
              <div style="display: flex; flex-direction: column; align-items: center; width: 45%;">
                <video id="dollyzoom1" autoplay controls muted loop playsinline style="width: 100%;">
                  <source src="./static/videos/ReVLA_flip_bridge/Place the cup on the blue plate/2-rollout.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <p style="margin-top: 10px; font-size: 1em;">ReVLA</p>
              </div>
            
  
              <div style="display: flex; flex-direction: column; align-items: center; width: 45%;">
                <video id="dollyzoom1" autoplay controls muted loop playsinline style="width: 100%;">
                  <source src="./static/videos/openvla-7b/Place the cup on the blue plate/2-rollout.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <p style="margin-top: 10px; font-size: 1em;">OpenVLA</p>
              </div>
            </div>
          <p style="text-align: center;">
              Task Prompt : Pick up the cup and place it on the specified plate  
          </p>
        
          <!-- Add a horizontal line  -->
          <hr style="border: 1px solid #000000;">
          <p>
            <strong> Indomain Task + Objects </strong>: In these episodes we use the same objects as in the bridge dataset and try to test the drop in performance for the indomain tasks. 
          </p>

          <div style="display: flex; justify-content: center; align-items: flex-start; gap: 20px;">
            <!-- Video 1 with Caption Below -->

            <div style="display: flex; justify-content: center; align-items: flex-start; gap: 20px;">
              <!-- Video 1 with Caption Below -->
              <div style="display: flex; flex-direction: column; align-items: center; width: 45%;">
                <video id="dollyzoom1" autoplay controls muted loop playsinline style="width: 100%;">
                  <source src="./static/videos/ReVLA_flip_bridge/Pick up the banana and place it in the pan/1-rollout.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                </video>
                <p style="margin-top: 10px; font-size: 1em;">ReVLA</p>
              </div>
            
  
              <div style="display: flex; flex-direction: column; align-items: center; width: 45%;">
                <video id="dollyzoom1" autoplay controls muted loop playsinline style="width: 100%;">
                  <source src="./static/videos/openvla-7b/Pick up the banana and place it in the pan/1-rollout.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  
                </video>
                <p style="margin-top: 10px; font-size: 1em;">OpenVLA</p>
              </div>
            </div>
          </div>
          <p style="text-align: center;">
            Task Prompt : Pick up the carrot and place it on the plate   
            </p>
          



      </div>

      </div>
    </div>
  </div>
</section>

<!-- <section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->


<!-- <section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Recent progress in large language models and
            access to large-scale robotic datasets has sparked a paradigm
            shift in robotics models transforming them into generalists
            able to adapt to various tasks, scenes, and robot modalities.
            A large step for the community are open Vision Language
            Action models which showcase strong performance in a wide
            variety of tasks. In this work, we study the visual generalization
            capabilities of three existing robotic foundation models, and
            propose a corresponding evaluation framework.
          </p>
          <p>
            Our study shows that the existing models do not exhibit
            robustness to visual out-of-domain scenarios. This is potentially caused by limited variations in the training data and/or
            catastrophic forgetting, leading to domain limitations in the
            vision foundation models. We further explore OpenVLA, which
            uses two pre-trained vision foundation models and is, therefore,
            expected to generalize to out-of-domain experiments. However,
            we showcase catastrophic forgetting by DINO-v2 in OpenVLA
            through its failure to fulfill the task of depth regression.
          </p>
          
          <p>
            To overcome the aforementioned issue of visual catastrophic
            forgetting, we propose a gradual backbone reversal approach
            founded on model merging. This enables OpenVLA - which
            requires the adaptation of the visual backbones during initial
            training - to regain its visual generalization ability. Regaining
            this capability enables our ReVLA model to improve over
            OpenVLA by a factor of 77% and 66% for grasping and lifting
            in visual OOD tasks. We will make our source code and OOD
            evaluation framework publicly available.
          </p>

        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  <!-- </div>  -->
<!-- </section> --> 
<!-- 
<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div> -->
    <!--/ Matting. -->

    <!-- Animation. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2>

        <!-- Interpolating. -->
        <!-- <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div> -->
        <!-- <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div> -->
        <!-- <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3> -->
        <!-- <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div> -->
        <!-- <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="./static/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      <!-- </div>
    </div>  -->
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div> -->
    <!--/ Concurrent Work. -->

  <!-- </div> --> 
<!-- </section> --> 

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{dey2024revlarevertingvisualdomain,
      title={ReVLA: Reverting Visual Domain Limitation of Robotic Foundation Models}, 
      author={Sombit Dey and Jan-Nico Zaech and Nikolay Nikolov and Luc Van Gool and Danda Pani Paudel},
      year={2024},
      eprint={2409.15250},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2409.15250}, 
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">

    <div class="columns margin-right">
      <div class="column is-8">
        <div class="content">
          <p>
            Thanks a lot to <a href="https://keunhong.com/">Keunhong</a> for the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project Template!!!
            
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
